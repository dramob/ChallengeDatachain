{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def scrape_article(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erreur lors de l'accès à la page {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    title = soup.find('h1')  # Ajustez le sélecteur si nécessaire\n",
    "    # Extraction de la date en utilisant la classe 'itemDateCreated'\n",
    "    date_span = soup.find('span', class_='itemDateCreated')\n",
    "    date = date_span.get_text().strip().replace('Date de création:', '').strip() if date_span else \"Date non trouvée\"\n",
    "    author = soup.find('div', class_='author')  # Ajustez si nécessaire\n",
    "\n",
    "    content_container = soup.find('div', class_='itemIntroText')\n",
    "    if content_container:\n",
    "        content_parts = content_container.find_all('p', class_='texte textearticle')\n",
    "        content = ' '.join(p.text.strip() for p in content_parts)\n",
    "    else:\n",
    "        content = \"Contenu non trouvé\"\n",
    "\n",
    "    article = {\n",
    "        'url': url,\n",
    "        'title': title.text.strip() if title else \"Titre non trouvé\",\n",
    "        'date': date,\n",
    "        'author': author.text.strip() if author else \"Auteur non trouvé\",\n",
    "        'content': content\n",
    "    }\n",
    "    \n",
    "    return article\n",
    "\n",
    "def main():\n",
    "    urls = [\n",
    "        \"https://www.agenceecofin.com/formation/1804-117979-le-japon-ouvre-les-candidatures-2025-de-son-programme-de-bourses-aux-etudiants-etrangers\",\n",
    "        \"https://www.agenceecofin.com/entreprendre/1804-117982-google-propose-un-programme-de-formation-et-de-mentorat-aux-start-up-du-secteur-de-l-education\",\n",
    "        \"https://www.agenceecofin.com/gestion-publique/2204-118042-burkina-le-gouvernement-devoile-des-projets-de-cooperation-educative-avec-la-russie\"\n",
    "    ]\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    for url in urls:\n",
    "        article = scrape_article(url)\n",
    "        if article:\n",
    "            articles.append(article)\n",
    "    \n",
    "    # Sauvegarde en JSON\n",
    "    with open('articles.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(articles, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Processing Data with OpenAI\n",
    "\n",
    "In this Jupyter Notebook, we demonstrate how to load, process, and use data for generating responses with OpenAI's GPT-3.5. We will walk through the steps of loading articles from a JSON file, vectorizing article content, finding the most relevant article based on a query, and generating responses using OpenAI's model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, we import the necessary libraries and set up the environment for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai>=0.10.0 in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.25.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.4.1.post1)\n",
      "Requirement already satisfied: python-dotenv>=0.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.19.2 in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from openai>=0.10.0->-r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (4.40.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (0.23.0)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.10/site-packages (from sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (10.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.24->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from scikit-learn>=0.24->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=0.10.0->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=0.10.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=0.10.0->-r requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=0.10.0->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0.10.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.10.0->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=0.10.0->-r requirements.txt (line 1)) (2.18.2)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/codespace/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.0.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai.types import Completion, CompletionChoice, CompletionUsage\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Articles from JSON\n",
    "\n",
    "This section covers how to load articles from a JSON file. The file should be structured as an array of articles, each with fields for URL, title, date, author, and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        articles = json.load(file)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Article Content\n",
    "\n",
    "We use the Sentence-BERT model to convert article contents into vector embeddings. This will facilitate the calculation of semantic similarity between a user's query and the articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_articles(articles):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    for article in articles:\n",
    "        article['embedding'] = model.encode(article['content'][:512], convert_to_tensor=True)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Most Similar Article\n",
    "\n",
    "Here, we define a function to find the article most similar to a given query using cosine similarity between the query and article embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_article(query, articles):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    similarities = [cosine_similarity(query_embedding.reshape(1, -1), article['embedding'].reshape(1, -1))[0][0] for article in articles]\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return articles[most_similar_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Responses Using OpenAI's GPT-3\n",
    "\n",
    "Once we have identified the most relevant article, we can generate a response by feeding the article content along with the query into the GPT-3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_with_gpt3(article, query):\n",
    "    try:\n",
    "        chat_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust the model as necessary\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "                {\"role\": \"assistant\", \"content\": article['content'][:1024]}  # Including article context\n",
    "            ]\n",
    "        )\n",
    "        # Utilisation des propriétés directes des objets pour obtenir le contenu\n",
    "        response_content = \"\\u200B\\n\\n\" + chat_response.choices[0].message.content\n",
    "        return response_content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main  TEST Execution Function\n",
    "\n",
    "The `main` function orchestrates the loading, processing, and querying of articles. It also outputs the generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: ​\n",
      "\n",
      "japonaise pour poursuivre leurs études dans leur domaine d'intérêt. Les bourses couvrent les frais de scolarité, les frais de voyage aller-retour, une allocation mensuelle, ainsi que d'autres avantages. Le Japon est réputé pour ses avancées technologiques, sa culture riche et fascinante, sa cuisine délicieuse et sa société bien organisée. Le pays offre une combinaison unique de tradition et de modernité, avec des temples anciens côtoyant des gratte-ciel ultramodernes. Les Japonais sont connus pour leur politesse, leur sens du devoir et leur efficacité au travail. La culture japonaise regorge d'art, de musique, d'architecture, de littérature et de nombreux autres aspects qui la rendent captivante. N'hésitez pas à explorer davantage la culture japonaise si vous êtes intéressé par ce pays fascinant !\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    articles = load_articles('articles.json')\n",
    "    articles = vectorize_articles(articles)\n",
    "    query = \"Bonjour. Que peux tu me dire sur le japon \"\n",
    "    most_similar_article = find_most_similar_article(query, articles)\n",
    "    response = generate_response_with_gpt3(most_similar_article, query)\n",
    "    print(\"Generated Response:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
